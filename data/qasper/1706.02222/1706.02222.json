{
  "paper_id": "1706.02222",
  "title": "Gated Recurrent Neural Tensor Network",
  "questions": [
    {
      "question": "How much improvement do the introduced model achieve compared to the previous models?",
      "free_form_answer": "GRURNTN, character: 0.06 absolute / 4.32% relative bits-per-character.\nLSTMRNTN, character: 0.03 absolute / 2.22% relative bits-per-character.\nGRURNTN, word: 10.4 absolute / 10.63% relative perplexity.\nLSTMRNTN, word: 11.29 absolute / 10.42% relative perplexity.",
      "evidence": [
        "Table 1 shows PTB test set BPC among our baseline models, our proposed models and several published results. Our proposed model GRURNTN and LSTMRNTN outperformed both baseline models. GRURNTN reduced the BPC from 1.39 to 1.33 (0.06 absolute / 4.32% relative BPC) from the baseline GRURNN, and LSTMRNTN reduced the BPC from 1.37 to 1.34 (0.03 absolute / 2.22% relative BPC) from the baseline LSTMRNN. Overall, GRURNTN slightly outperformed LSTMRNTN, and both proposed models outperformed all of the baseline models on the character-level language modeling task.",
        "Table 1 shows the PTB test set PPL among our baseline models, proposed models, and several published results. Both our proposed models outperformed their baseline models. GRURNTN reduced the perplexity from 97.78 to 87.38 (10.4 absolute / 10.63% relative PPL) over the baseline GRURNN and LSTMRNTN reduced the perplexity from 108.26 to 96.97 (11.29 absolute / 10.42% relative PPL) over the baseline LSTMRNN. Overall, LSTMRNTN improved the LSTMRNN model and its performance closely resembles the baseline GRURNN. However, GRURNTN outperformed all the baseline models as well as the other models by a large margin."
      ],
      "highlighted_evidence": [
        "GRURNTN reduced the BPC from 1.39 to 1.33 (0.06 absolute / 4.32% relative BPC) from the baseline GRURNN, and LSTMRNTN reduced the BPC from 1.37 to 1.34 (0.03 absolute / 2.22% relative BPC) from the baseline LSTMRNN.",
        "GRURNTN reduced the perplexity from 97.78 to 87.38 (10.4 absolute / 10.63% relative PPL) over the baseline GRURNN and LSTMRNTN reduced the perplexity from 108.26 to 96.97 (11.29 absolute / 10.42% relative PPL) over the baseline LSTMRNN."
      ]
    }
  ]
}